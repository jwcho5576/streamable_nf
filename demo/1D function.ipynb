{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "from metrics import MSE\n",
    "from network import ProgressiveSiren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1D scalar function fitting (Sec. 4.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set random seed\n",
    "random_seed = 31210\n",
    "torch.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#create synthetic target function\n",
    "x = torch.linspace(0, 1, steps = 200)\n",
    "y = torch.zeros_like(x)\n",
    "n_modes = 10\n",
    "f = 5\n",
    "pi = 3.14159\n",
    "for i in range(n_modes):\n",
    "    phase = torch.rand(1) * 2 * pi\n",
    "    y += torch.sin(2 * pi * f * x + phase)\n",
    "    f += 5\n",
    "x, y = torch.unsqueeze(x.to(device), 1), torch.unsqueeze(y.to(device), 1)\n",
    "\n",
    "#visualize target ground truth function\n",
    "print(\"ground truth\")\n",
    "plt.plot(x.cpu(), y.cpu(), 'y')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the streamable neural field network\n",
    "starting_width = 10\n",
    "increased_width = 10\n",
    "n_subnets = 4\n",
    "\n",
    "net = ProgressiveSiren(in_feats = 1, hidden_feats = starting_width, n_hidden_layers = 3, out_feats = 1)\n",
    "net.to(device)\n",
    "print(net)\n",
    "\n",
    "lr = 1e-4\n",
    "epochs = 150\n",
    "# loss function\n",
    "mse = MSE()\n",
    "trained_widths = [starting_width]\n",
    "\n",
    "#training loop\n",
    "for i in range(n_subnets):\n",
    "    if i != 0:\n",
    "        net.grow_width(width = increased_width)\n",
    "        trained_widths.append(trained_widths[-1] + increased_width)\n",
    "    net.select_subnet(i)\n",
    "    optimizer = optim.Adam(net.parameters(), lr = lr)\n",
    "    print(\"current width: {}\".format(trained_widths[-1]))\n",
    "    for e in tqdm(range(epochs)):\n",
    "        optimizer.zero_grad()               # clear gradients\n",
    "        yhat = net(x)                       # forward prop.\n",
    "        loss = mse(yhat, y)                 # compute loss\n",
    "        loss.backward()                     # backward prop.\n",
    "        if i > 0:\n",
    "            net.freeze_subnet(i - 1)        # clear gradients of pretrained sub-network\n",
    "        optimizer.step()                    # update weights\n",
    "\n",
    "    print(\"MSE:\", loss.detach().cpu().numpy())\n",
    "    print()\n",
    "print(\"training done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize output\n",
    "ax = []\n",
    "fig = plt.figure(figsize = (36, 10))\n",
    "\n",
    "with torch.no_grad():\n",
    "    net.eval()\n",
    "    for i, w in enumerate(trained_widths):\n",
    "        net.select_subnet(i)    # select sub-network\n",
    "        yhat = net(x)           # forward prop.\n",
    "        ax.append(fig.add_subplot(2, 4, i + 1))\n",
    "        ax[i].plot(x.cpu(), y.cpu(), 'y--', label = 'gt')\n",
    "        ax[i].plot(x.cpu(), yhat.cpu(), 'g', label = 'width: {}'.format(w))\n",
    "        plt.ylim(-5.7, 4.7)\n",
    "        plt.grid(True)\n",
    "        plt.legend(loc = 'lower left', fontsize = 15)\n",
    "        plt.title(f'width: {w}', fontsize = 20)\n",
    "    for i, w in enumerate(trained_widths):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        net.select_subnet(i)                # select sub-network\n",
    "        yhat_res = net.forward_residual(x)  # forward prop. for residual output\n",
    "        ax.append(fig.add_subplot(2, 4, i + 5))\n",
    "        ax[i + 3].plot(x.cpu(), yhat_res.cpu(), 'k', label = 'width: {}'.format(w))\n",
    "        plt.ylim(-5.7, 4.7) \n",
    "        plt.grid(True)\n",
    "        plt.legend(loc = 'lower left', fontsize = 15)\n",
    "        plt.title(f'width: {w} (residual)', fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "88e944612da00620aa4f7ffbdfd005a4177fff04bf0dc489f6e73f9c60a7a452"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('pnf': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
